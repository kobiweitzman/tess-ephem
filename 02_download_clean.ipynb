{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba0272ff-9a39-4039-a18a-cd40a6da5481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: TOI 1801.01 (TIC 119584412)\n",
      " PDCSAP S22: ok (N=16102)\n",
      " PDCSAP S49: ok (N=13272)\n",
      "  FFI S22: skip (already have PDCSAP)\n",
      "  FFI S49: skip (already have PDCSAP)\n",
      "\n",
      "== DONE ==\n",
      "Saved figure: figures/TIC119584412_download_clean.png\n",
      "Saved JSON  : results/TIC119584412_download_clean_summary.json\n",
      "Summary: {'target_toi': 'TOI 1801.01', 'target_tic': 119584412, 'n_sectors_pdcsap': 2, 'n_sectors_ffi': 0, 'sectors_pdcsap': [22, 49], 'sectors_ffi': [], 'n_points_raw': 29374, 'n_points_flat': 29374, 'rms_raw_ppm': 1359.3999901786447, 'rms_flat_ppm': 1099.746714683546, 'cdpp1h_flat_ppm': 251.16073602817906, 'flatten_window_days': 1.0, 'notes': 'PDCSAP preferred; FFI(TESSCut) used where SPOC PDCSAP missing.'}\n"
     ]
    }
   ],
   "source": [
    "# 02_download_clean — Target A (PDCSAP-first, TESSCut-FFI fallback) — robust & batchable\n",
    "import json, warnings, pathlib, re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# --- Config (single-target defaults) ---\n",
    "TARGET_TOI = \"TOI 1801.01\"\n",
    "TARGET_TIC = 119584412\n",
    "QUALITY    = 175\n",
    "CUTOUT_SZ  = 15\n",
    "WIN_DAYS   = 1.0\n",
    "\n",
    "# --- Folders ---\n",
    "pathlib.Path(\"figures\").mkdir(exist_ok=True)\n",
    "pathlib.Path(\"results\").mkdir(exist_ok=True)\n",
    "pathlib.Path(\"data_raw_fresh\").mkdir(exist_ok=True)\n",
    "\n",
    "# --- Helpers ---\n",
    "def window_len_for(t_days, window_days=1.0):\n",
    "    dt = np.nanmedian(np.diff(t_days))\n",
    "    wl = 401 if (not np.isfinite(dt) or dt<=0) else max(5, int(round(window_days/dt)))\n",
    "    return wl if wl % 2 == 1 else wl + 1\n",
    "\n",
    "def savgol_trend(t, y, window_len, polyorder=2):\n",
    "    half = window_len//2\n",
    "    trend = np.full_like(y, np.nan, dtype=float)\n",
    "    for i in range(len(y)):\n",
    "        lo, hi = max(0, i-half), min(len(y), i+half+1)\n",
    "        tt = t[lo:hi] - t[i]; yy = y[lo:hi]\n",
    "        m  = np.isfinite(tt) & np.isfinite(yy)\n",
    "        if np.count_nonzero(m) >= polyorder+1:\n",
    "            c = np.polyfit(tt[m], yy[m], polyorder)\n",
    "            trend[i] = np.polyval(c, 0.0)\n",
    "    trend[~np.isfinite(trend)] = np.nanmedian(y)\n",
    "    return trend\n",
    "\n",
    "def custom_flatten(lc, window_days=1.0, polyorder=2):\n",
    "    \"\"\"Return a *new* LightCurve with flattened flux (no .replace() calls).\"\"\"\n",
    "    t = lc.time.value\n",
    "    f = lc.flux.value.astype(float)\n",
    "    wl = window_len_for(t, window_days)\n",
    "    tr = savgol_trend(t, f, wl, polyorder=polyorder)\n",
    "    flat = f/np.where(np.isfinite(tr), tr, np.nanmedian(f))\n",
    "    flat /= np.nanmedian(flat)\n",
    "    # carry flux_err if present\n",
    "    try:\n",
    "        ferr = lc.flux_err.value if getattr(lc, \"flux_err\", None) is not None else None\n",
    "    except Exception:\n",
    "        ferr = None\n",
    "    from lightkurve import LightCurve\n",
    "    return LightCurve(time=lc.time, flux=flat, flux_err=ferr, meta=dict(getattr(lc, \"meta\", {})))\n",
    "\n",
    "def approx_cdpp_ppm(lc, hours=1.0):\n",
    "    t = lc.time.value; f = lc.flux.value\n",
    "    dt_hr = np.nanmedian(np.diff(t))*24.0\n",
    "    if not np.isfinite(dt_hr) or dt_hr<=0: return float(\"nan\")\n",
    "    n = max(1, int(round(hours/dt_hr)))\n",
    "    run = np.convolve(f - np.nanmedian(f), np.ones(n)/n, mode=\"valid\")\n",
    "    return float(np.nanstd(run)*1e6)\n",
    "\n",
    "def get_header_sector(header):\n",
    "    # Try common sector keys; then regex fallback\n",
    "    for k in (\"SECTOR\",\"sector\",\"SEC1\"):\n",
    "        try:\n",
    "            v = header.get(k)\n",
    "            if v is not None:\n",
    "                return int(v)\n",
    "        except Exception:\n",
    "            pass\n",
    "    txt = \" \".join([f\"{k}={header.get(k)}\" for k in header.keys()])\n",
    "    m = re.search(r\"[Ss]ector[^0-9]*([0-9]{1,3})\", txt)\n",
    "    return int(m.group(1)) if m else None\n",
    "\n",
    "# --- Lightkurve ---\n",
    "import lightkurve as lk\n",
    "from lightkurve import LightCurveCollection\n",
    "\n",
    "def run_download_clean(target_toi: str, target_tic: int, quality=QUALITY, cutout_sz=CUTOUT_SZ, win_days=WIN_DAYS):\n",
    "    TARGET = f\"TIC {target_tic}\"\n",
    "    out_fig  = f\"figures/TIC{target_tic}_download_clean.png\"\n",
    "    out_json = f\"results/TIC{target_tic}_download_clean_summary.json\"\n",
    "\n",
    "    print(f\"Target: {target_toi} ({TARGET})\")\n",
    "\n",
    "    # -------------------------\n",
    "    # 1) Download SPOC PDCSAP first; read sector from files (robust to missing 'sector' column)\n",
    "    # -------------------------\n",
    "    pdcsap_list, got_spoc_sectors = [], set()\n",
    "    sr_spoc = lk.search_lightcurvefile(TARGET, mission=\"TESS\", author=\"SPOC\")\n",
    "\n",
    "    if len(sr_spoc) == 0:\n",
    "        print(\"No SPOC PDCSAP products found.\")\n",
    "    else:\n",
    "        for i in range(len(sr_spoc)):\n",
    "            try:\n",
    "                lcf = sr_spoc[i].download(download_dir=\"data_raw_fresh\")\n",
    "                lc  = lcf.PDCSAP_FLUX.remove_nans().normalize()\n",
    "                # sector from object or header\n",
    "                s = getattr(lcf, \"sector\", None)\n",
    "                if s is None:\n",
    "                    try:\n",
    "                        hdr = lcf.header() if hasattr(lcf, \"header\") else lcf.get_header()\n",
    "                    except Exception:\n",
    "                        hdr = None\n",
    "                    if hdr is not None:\n",
    "                        s = get_header_sector(hdr)\n",
    "                if s is None: s = -1\n",
    "                lc.meta[\"source\"] = \"PDCSAP\"; lc.meta[\"sector\"] = int(s)\n",
    "                pdcsap_list.append(lc)\n",
    "                if s != -1: got_spoc_sectors.add(int(s))\n",
    "                print(f\" PDCSAP S{int(s) if s!=-1 else '?'}: ok (N={len(lc)})\")\n",
    "            except Exception as e:\n",
    "                print(f\" PDCSAP entry {i}: failed -> {e}\")\n",
    "\n",
    "    # -------------------------\n",
    "    # 2) Query TESSCut and add FFI for sectors not covered by PDCSAP\n",
    "    # -------------------------\n",
    "    ffi_list = []\n",
    "    try:\n",
    "        sr_cut = lk.search_tesscut(TARGET)\n",
    "    except Exception as e:\n",
    "        sr_cut = []\n",
    "        print(\"TESSCut query failed:\", e)\n",
    "\n",
    "    if len(sr_cut) == 0:\n",
    "        print(\"No TESSCut entries found.\")\n",
    "    else:\n",
    "        for i in range(len(sr_cut)):\n",
    "            try:\n",
    "                tpf = sr_cut[i].download(cutout_size=cutout_sz, download_dir=\"data_raw_fresh\")\n",
    "                # sector from object or header\n",
    "                s = getattr(tpf, \"sector\", None)\n",
    "                if s is None:\n",
    "                    try:\n",
    "                        hdr = tpf.hdu[0].header\n",
    "                    except Exception:\n",
    "                        hdr = None\n",
    "                    if hdr is not None:\n",
    "                        s = get_header_sector(hdr)\n",
    "                if s is None: s = -1\n",
    "                # skip if PDCSAP already covers\n",
    "                if (s != -1) and (int(s) in got_spoc_sectors):\n",
    "                    print(f\"  FFI S{int(s)}: skip (already have PDCSAP)\")\n",
    "                    continue\n",
    "                # aperture photometry\n",
    "                mask = tpf.create_threshold_mask(threshold=3, reference_pixel=None)\n",
    "                if not np.any(mask):\n",
    "                    m = np.zeros_like(mask, dtype=bool)\n",
    "                    yy, xx = np.unravel_index(np.nanargmax(np.nanmedian(tpf.flux.value, axis=0)), mask.shape)\n",
    "                    m[yy, xx] = True\n",
    "                    mask = m\n",
    "                lc = tpf.to_lightcurve(aperture_mask=mask).remove_nans().normalize()\n",
    "                lc.meta[\"source\"] = \"FFI\"; lc.meta[\"sector\"] = int(s)\n",
    "                ffi_list.append(lc)\n",
    "                print(f\"  FFI S{int(s) if s!=-1 else '?'}: ok (N={len(lc)})\")\n",
    "            except Exception as e:\n",
    "                print(f\"  FFI entry {i}: failed -> {e}\")\n",
    "\n",
    "    if not (pdcsap_list or ffi_list):\n",
    "        raise RuntimeError(\"No light curves obtained from SPOC or TESSCut.\")\n",
    "\n",
    "    # -------------------------\n",
    "    # 3) Stitch, flatten, QC\n",
    "    # -------------------------\n",
    "    all_lcs_raw   = pdcsap_list + ffi_list\n",
    "    stitched_raw  = LightCurveCollection(all_lcs_raw).stitch().remove_nans()\n",
    "    stitched_flat = custom_flatten(stitched_raw, window_days=win_days)\n",
    "\n",
    "    def rms_ppm(x): return float(np.nanstd(x)*1e6)\n",
    "    qc = {\n",
    "        \"target_toi\": target_toi,\n",
    "        \"target_tic\": target_tic,\n",
    "        \"n_sectors_pdcsap\": len(pdcsap_list),\n",
    "        \"n_sectors_ffi\": len(ffi_list),\n",
    "        \"sectors_pdcsap\": [int(lc.meta.get(\"sector\", -1)) for lc in pdcsap_list],\n",
    "        \"sectors_ffi\": [int(lc.meta.get(\"sector\", -1)) for lc in ffi_list],\n",
    "        \"n_points_raw\": int(len(stitched_raw)),\n",
    "        \"n_points_flat\": int(len(stitched_flat)),\n",
    "        \"rms_raw_ppm\": rms_ppm(stitched_raw.flux.value),\n",
    "        \"rms_flat_ppm\": rms_ppm(stitched_flat.flux.value),\n",
    "        \"cdpp1h_flat_ppm\": approx_cdpp_ppm(stitched_flat, hours=1.0),\n",
    "        \"flatten_window_days\": float(win_days),\n",
    "        \"notes\": \"PDCSAP preferred; FFI(TESSCut) used where SPOC PDCSAP missing.\"\n",
    "    }\n",
    "\n",
    "    # -------------------------\n",
    "    # 4) Figure & JSON\n",
    "    # -------------------------\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12,6), dpi=140, sharex=True)\n",
    "    stitched_raw.plot(ax=ax1, marker=\".\", lw=0, alpha=0.35)\n",
    "    ax1.set_ylabel(\"Flux (norm)\")\n",
    "    ax1.set_title(f\"{target_toi} (TIC {target_tic}) — Stitched RAW\")\n",
    "    stitched_flat.plot(ax=ax2, marker=\".\", lw=0, alpha=0.45, label=\"flattened\")\n",
    "    ax2.set_xlabel(\"Time [BTJD]\")\n",
    "    ax2.set_ylabel(\"Flux (norm)\")\n",
    "    ax2.set_title(f\"{target_toi} — Stitched FLAT (window={win_days:.2f} d)\")\n",
    "    ax2.legend(loc=\"best\")\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(out_fig); plt.close(fig)\n",
    "\n",
    "    with open(out_json, \"w\") as f:\n",
    "        json.dump(qc, f, indent=2)\n",
    "\n",
    "    print(\"\\n== DONE ==\")\n",
    "    print(f\"Saved figure: {out_fig}\")\n",
    "    print(f\"Saved JSON  : {out_json}\")\n",
    "    print(\"Summary:\", qc)\n",
    "\n",
    "    return qc, out_fig, out_json\n",
    "\n",
    "# ---------- Run on Target A (deliverable) ----------\n",
    "_ = run_download_clean(TARGET_TOI, TARGET_TIC, quality=QUALITY, cutout_sz=CUTOUT_SZ, win_days=WIN_DAYS)\n",
    "\n",
    "# ---------- OPTIONAL: batch-run first 4 priority targets ----------\n",
    "# Set RUN_BATCH=True to run on the first 4 rows in results/priority_targets.csv\n",
    "RUN_BATCH = False\n",
    "if RUN_BATCH:\n",
    "    import pandas as pd\n",
    "    dfp = pd.read_csv(\"results/priority_targets.csv\")\n",
    "    # Expect columns: TIC_ID_norm, toi (string/number). Adjust if your headers differ.\n",
    "    for _, row in dfp.head(4).iterrows():\n",
    "        tic = int(row[\"TIC_ID_norm\"])\n",
    "        toi = f\"TOI {row['toi']}\"\n",
    "        try:\n",
    "            run_download_clean(toi, tic, quality=QUALITY, cutout_sz=CUTOUT_SZ, win_days=WIN_DAYS)\n",
    "        except Exception as e:\n",
    "            print(f\"[Batch] {toi} (TIC {tic}) failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df68e38b-8753-409d-b23c-dc914e1dc224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: TOI 260.01 (TIC 37749396)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: 30% (5871/19412) of the cadences will be ignored due to the quality mask (quality_bitmask=175).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " PDCSAP S3: ok (N=12978)\n",
      " PDCSAP S42: ok (N=11473)\n",
      " PDCSAP S70: ok (N=86180)\n",
      " PDCSAP S70: ok (N=14424)\n",
      "  FFI S3: skip (already have PDCSAP)\n",
      "  FFI S42: skip (already have PDCSAP)\n",
      "  FFI S70: skip (already have PDCSAP)\n",
      "\n",
      "== DONE ==\n",
      "Saved figure: figures/TIC37749396_download_clean.png\n",
      "Saved JSON  : results/TIC37749396_download_clean_summary.json\n",
      "Summary: {'target_toi': 'TOI 260.01', 'target_tic': 37749396, 'n_sectors_pdcsap': 4, 'n_sectors_ffi': 0, 'sectors_pdcsap': [3, 42, 70, 70], 'sectors_ffi': [], 'n_points_raw': 125055, 'n_points_flat': 125055, 'rms_raw_ppm': 1043.9811740070581, 'rms_flat_ppm': 1035.729219446299, 'cdpp1h_flat_ppm': 112.01310543832174, 'flatten_window_days': 1.0, 'notes': 'PDCSAP preferred; FFI(TESSCut) used where SPOC PDCSAP missing.'}\n"
     ]
    }
   ],
   "source": [
    "# 02_download_clean — Target A (PDCSAP-first, TESSCut-FFI fallback) — robust & batchable\n",
    "import json, warnings, pathlib, re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# --- Config (single-target defaults) ---\n",
    "TARGET_TOI= \"TOI 260.01\"\n",
    "TARGET_TIC= 37749396\n",
    "QUALITY    = 175\n",
    "CUTOUT_SZ  = 15\n",
    "WIN_DAYS   = 1.0\n",
    "\n",
    "# --- Folders ---\n",
    "pathlib.Path(\"figures\").mkdir(exist_ok=True)\n",
    "pathlib.Path(\"results\").mkdir(exist_ok=True)\n",
    "pathlib.Path(\"data_raw_fresh\").mkdir(exist_ok=True)\n",
    "\n",
    "# --- Helpers ---\n",
    "def window_len_for(t_days, window_days=1.0):\n",
    "    dt = np.nanmedian(np.diff(t_days))\n",
    "    wl = 401 if (not np.isfinite(dt) or dt<=0) else max(5, int(round(window_days/dt)))\n",
    "    return wl if wl % 2 == 1 else wl + 1\n",
    "\n",
    "def savgol_trend(t, y, window_len, polyorder=2):\n",
    "    half = window_len//2\n",
    "    trend = np.full_like(y, np.nan, dtype=float)\n",
    "    for i in range(len(y)):\n",
    "        lo, hi = max(0, i-half), min(len(y), i+half+1)\n",
    "        tt = t[lo:hi] - t[i]; yy = y[lo:hi]\n",
    "        m  = np.isfinite(tt) & np.isfinite(yy)\n",
    "        if np.count_nonzero(m) >= polyorder+1:\n",
    "            c = np.polyfit(tt[m], yy[m], polyorder)\n",
    "            trend[i] = np.polyval(c, 0.0)\n",
    "    trend[~np.isfinite(trend)] = np.nanmedian(y)\n",
    "    return trend\n",
    "\n",
    "def custom_flatten(lc, window_days=1.0, polyorder=2):\n",
    "    \"\"\"Return a *new* LightCurve with flattened flux (no .replace() calls).\"\"\"\n",
    "    t = lc.time.value\n",
    "    f = lc.flux.value.astype(float)\n",
    "    wl = window_len_for(t, window_days)\n",
    "    tr = savgol_trend(t, f, wl, polyorder=polyorder)\n",
    "    flat = f/np.where(np.isfinite(tr), tr, np.nanmedian(f))\n",
    "    flat /= np.nanmedian(flat)\n",
    "    # carry flux_err if present\n",
    "    try:\n",
    "        ferr = lc.flux_err.value if getattr(lc, \"flux_err\", None) is not None else None\n",
    "    except Exception:\n",
    "        ferr = None\n",
    "    from lightkurve import LightCurve\n",
    "    return LightCurve(time=lc.time, flux=flat, flux_err=ferr, meta=dict(getattr(lc, \"meta\", {})))\n",
    "\n",
    "def approx_cdpp_ppm(lc, hours=1.0):\n",
    "    t = lc.time.value; f = lc.flux.value\n",
    "    dt_hr = np.nanmedian(np.diff(t))*24.0\n",
    "    if not np.isfinite(dt_hr) or dt_hr<=0: return float(\"nan\")\n",
    "    n = max(1, int(round(hours/dt_hr)))\n",
    "    run = np.convolve(f - np.nanmedian(f), np.ones(n)/n, mode=\"valid\")\n",
    "    return float(np.nanstd(run)*1e6)\n",
    "\n",
    "def get_header_sector(header):\n",
    "    # Try common sector keys; then regex fallback\n",
    "    for k in (\"SECTOR\",\"sector\",\"SEC1\"):\n",
    "        try:\n",
    "            v = header.get(k)\n",
    "            if v is not None:\n",
    "                return int(v)\n",
    "        except Exception:\n",
    "            pass\n",
    "    txt = \" \".join([f\"{k}={header.get(k)}\" for k in header.keys()])\n",
    "    m = re.search(r\"[Ss]ector[^0-9]*([0-9]{1,3})\", txt)\n",
    "    return int(m.group(1)) if m else None\n",
    "\n",
    "# --- Lightkurve ---\n",
    "import lightkurve as lk\n",
    "from lightkurve import LightCurveCollection\n",
    "\n",
    "def run_download_clean(target_toi: str, target_tic: int, quality=QUALITY, cutout_sz=CUTOUT_SZ, win_days=WIN_DAYS):\n",
    "    TARGET = f\"TIC {target_tic}\"\n",
    "    out_fig  = f\"figures/TIC{target_tic}_download_clean.png\"\n",
    "    out_json = f\"results/TIC{target_tic}_download_clean_summary.json\"\n",
    "\n",
    "    print(f\"Target: {target_toi} ({TARGET})\")\n",
    "\n",
    "    # -------------------------\n",
    "    # 1) Download SPOC PDCSAP first; read sector from files (robust to missing 'sector' column)\n",
    "    # -------------------------\n",
    "    pdcsap_list, got_spoc_sectors = [], set()\n",
    "    sr_spoc = lk.search_lightcurvefile(TARGET, mission=\"TESS\", author=\"SPOC\")\n",
    "\n",
    "    if len(sr_spoc) == 0:\n",
    "        print(\"No SPOC PDCSAP products found.\")\n",
    "    else:\n",
    "        for i in range(len(sr_spoc)):\n",
    "            try:\n",
    "                lcf = sr_spoc[i].download(download_dir=\"data_raw_fresh\")\n",
    "                lc  = lcf.PDCSAP_FLUX.remove_nans().normalize()\n",
    "                # sector from object or header\n",
    "                s = getattr(lcf, \"sector\", None)\n",
    "                if s is None:\n",
    "                    try:\n",
    "                        hdr = lcf.header() if hasattr(lcf, \"header\") else lcf.get_header()\n",
    "                    except Exception:\n",
    "                        hdr = None\n",
    "                    if hdr is not None:\n",
    "                        s = get_header_sector(hdr)\n",
    "                if s is None: s = -1\n",
    "                lc.meta[\"source\"] = \"PDCSAP\"; lc.meta[\"sector\"] = int(s)\n",
    "                pdcsap_list.append(lc)\n",
    "                if s != -1: got_spoc_sectors.add(int(s))\n",
    "                print(f\" PDCSAP S{int(s) if s!=-1 else '?'}: ok (N={len(lc)})\")\n",
    "            except Exception as e:\n",
    "                print(f\" PDCSAP entry {i}: failed -> {e}\")\n",
    "\n",
    "    # -------------------------\n",
    "    # 2) Query TESSCut and add FFI for sectors not covered by PDCSAP\n",
    "    # -------------------------\n",
    "    ffi_list = []\n",
    "    try:\n",
    "        sr_cut = lk.search_tesscut(TARGET)\n",
    "    except Exception as e:\n",
    "        sr_cut = []\n",
    "        print(\"TESSCut query failed:\", e)\n",
    "\n",
    "    if len(sr_cut) == 0:\n",
    "        print(\"No TESSCut entries found.\")\n",
    "    else:\n",
    "        for i in range(len(sr_cut)):\n",
    "            try:\n",
    "                tpf = sr_cut[i].download(cutout_size=cutout_sz, download_dir=\"data_raw_fresh\")\n",
    "                # sector from object or header\n",
    "                s = getattr(tpf, \"sector\", None)\n",
    "                if s is None:\n",
    "                    try:\n",
    "                        hdr = tpf.hdu[0].header\n",
    "                    except Exception:\n",
    "                        hdr = None\n",
    "                    if hdr is not None:\n",
    "                        s = get_header_sector(hdr)\n",
    "                if s is None: s = -1\n",
    "                # skip if PDCSAP already covers\n",
    "                if (s != -1) and (int(s) in got_spoc_sectors):\n",
    "                    print(f\"  FFI S{int(s)}: skip (already have PDCSAP)\")\n",
    "                    continue\n",
    "                # aperture photometry\n",
    "                mask = tpf.create_threshold_mask(threshold=3, reference_pixel=None)\n",
    "                if not np.any(mask):\n",
    "                    m = np.zeros_like(mask, dtype=bool)\n",
    "                    yy, xx = np.unravel_index(np.nanargmax(np.nanmedian(tpf.flux.value, axis=0)), mask.shape)\n",
    "                    m[yy, xx] = True\n",
    "                    mask = m\n",
    "                lc = tpf.to_lightcurve(aperture_mask=mask).remove_nans().normalize()\n",
    "                lc.meta[\"source\"] = \"FFI\"; lc.meta[\"sector\"] = int(s)\n",
    "                ffi_list.append(lc)\n",
    "                print(f\"  FFI S{int(s) if s!=-1 else '?'}: ok (N={len(lc)})\")\n",
    "            except Exception as e:\n",
    "                print(f\"  FFI entry {i}: failed -> {e}\")\n",
    "\n",
    "    if not (pdcsap_list or ffi_list):\n",
    "        raise RuntimeError(\"No light curves obtained from SPOC or TESSCut.\")\n",
    "\n",
    "    # -------------------------\n",
    "    # 3) Stitch, flatten, QC\n",
    "    # -------------------------\n",
    "    all_lcs_raw   = pdcsap_list + ffi_list\n",
    "    stitched_raw  = LightCurveCollection(all_lcs_raw).stitch().remove_nans()\n",
    "    stitched_flat = custom_flatten(stitched_raw, window_days=win_days)\n",
    "\n",
    "    def rms_ppm(x): return float(np.nanstd(x)*1e6)\n",
    "    qc = {\n",
    "        \"target_toi\": target_toi,\n",
    "        \"target_tic\": target_tic,\n",
    "        \"n_sectors_pdcsap\": len(pdcsap_list),\n",
    "        \"n_sectors_ffi\": len(ffi_list),\n",
    "        \"sectors_pdcsap\": [int(lc.meta.get(\"sector\", -1)) for lc in pdcsap_list],\n",
    "        \"sectors_ffi\": [int(lc.meta.get(\"sector\", -1)) for lc in ffi_list],\n",
    "        \"n_points_raw\": int(len(stitched_raw)),\n",
    "        \"n_points_flat\": int(len(stitched_flat)),\n",
    "        \"rms_raw_ppm\": rms_ppm(stitched_raw.flux.value),\n",
    "        \"rms_flat_ppm\": rms_ppm(stitched_flat.flux.value),\n",
    "        \"cdpp1h_flat_ppm\": approx_cdpp_ppm(stitched_flat, hours=1.0),\n",
    "        \"flatten_window_days\": float(win_days),\n",
    "        \"notes\": \"PDCSAP preferred; FFI(TESSCut) used where SPOC PDCSAP missing.\"\n",
    "    }\n",
    "\n",
    "    # -------------------------\n",
    "    # 4) Figure & JSON\n",
    "    # -------------------------\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12,6), dpi=140, sharex=True)\n",
    "    stitched_raw.plot(ax=ax1, marker=\".\", lw=0, alpha=0.35)\n",
    "    ax1.set_ylabel(\"Flux (norm)\")\n",
    "    ax1.set_title(f\"{target_toi} (TIC {target_tic}) — Stitched RAW\")\n",
    "    stitched_flat.plot(ax=ax2, marker=\".\", lw=0, alpha=0.45, label=\"flattened\")\n",
    "    ax2.set_xlabel(\"Time [BTJD]\")\n",
    "    ax2.set_ylabel(\"Flux (norm)\")\n",
    "    ax2.set_title(f\"{target_toi} — Stitched FLAT (window={win_days:.2f} d)\")\n",
    "    ax2.legend(loc=\"best\")\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(out_fig); plt.close(fig)\n",
    "\n",
    "    with open(out_json, \"w\") as f:\n",
    "        json.dump(qc, f, indent=2)\n",
    "\n",
    "    print(\"\\n== DONE ==\")\n",
    "    print(f\"Saved figure: {out_fig}\")\n",
    "    print(f\"Saved JSON  : {out_json}\")\n",
    "    print(\"Summary:\", qc)\n",
    "\n",
    "    return qc, out_fig, out_json\n",
    "\n",
    "# ---------- Run on Target A (deliverable) ----------\n",
    "_ = run_download_clean(TARGET_TOI, TARGET_TIC, quality=QUALITY, cutout_sz=CUTOUT_SZ, win_days=WIN_DAYS)\n",
    "\n",
    "# ---------- OPTIONAL: batch-run first 4 priority targets ----------\n",
    "# Set RUN_BATCH=True to run on the first 4 rows in results/priority_targets.csv\n",
    "RUN_BATCH = False\n",
    "if RUN_BATCH:\n",
    "    import pandas as pd\n",
    "    dfp = pd.read_csv(\"results/priority_targets.csv\")\n",
    "    # Expect columns: TIC_ID_norm, toi (string/number). Adjust if your headers differ.\n",
    "    for _, row in dfp.head(4).iterrows():\n",
    "        tic = int(row[\"TIC_ID_norm\"])\n",
    "        toi = f\"TOI {row['toi']}\"\n",
    "        try:\n",
    "            run_download_clean(toi, tic, quality=QUALITY, cutout_sz=CUTOUT_SZ, win_days=WIN_DAYS)\n",
    "        except Exception as e:\n",
    "            print(f\"[Batch] {toi} (TIC {tic}) failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4729ef31-7dbd-4be7-a792-ca3ddd4c6647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: TOI 550.02 (TIC 311183180)\n",
      " PDCSAP S5: ok (N=17286)\n",
      " PDCSAP S31: ok (N=16250)\n",
      "  FFI S5: skip (already have PDCSAP)\n",
      "  FFI S31: skip (already have PDCSAP)\n",
      "\n",
      "== DONE ==\n",
      "Saved figure: figures/TIC311183180_download_clean.png\n",
      "Saved JSON  : results/TIC311183180_download_clean_summary.json\n",
      "Summary: {'target_toi': 'TOI 550.02', 'target_tic': 311183180, 'n_sectors_pdcsap': 2, 'n_sectors_ffi': 0, 'sectors_pdcsap': [5, 31], 'sectors_ffi': [], 'n_points_raw': 33536, 'n_points_flat': 33536, 'rms_raw_ppm': 3489.643335342407, 'rms_flat_ppm': 2277.229196109564, 'cdpp1h_flat_ppm': 2077.4277749925795, 'flatten_window_days': 1.0, 'notes': 'PDCSAP preferred; FFI(TESSCut) used where SPOC PDCSAP missing.'}\n"
     ]
    }
   ],
   "source": [
    "# 02_download_clean — Target A (PDCSAP-first, TESSCut-FFI fallback) — robust & batchable\n",
    "import json, warnings, pathlib, re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# --- Config (single-target defaults) ---\n",
    "TARGET_TOI=\"TOI 550.02\"\n",
    "TARGET_TIC=311183180\n",
    "QUALITY    = 175\n",
    "CUTOUT_SZ  = 15\n",
    "WIN_DAYS   = 1.0\n",
    "\n",
    "# --- Folders ---\n",
    "pathlib.Path(\"figures\").mkdir(exist_ok=True)\n",
    "pathlib.Path(\"results\").mkdir(exist_ok=True)\n",
    "pathlib.Path(\"data_raw_fresh\").mkdir(exist_ok=True)\n",
    "\n",
    "# --- Helpers ---\n",
    "def window_len_for(t_days, window_days=1.0):\n",
    "    dt = np.nanmedian(np.diff(t_days))\n",
    "    wl = 401 if (not np.isfinite(dt) or dt<=0) else max(5, int(round(window_days/dt)))\n",
    "    return wl if wl % 2 == 1 else wl + 1\n",
    "\n",
    "def savgol_trend(t, y, window_len, polyorder=2):\n",
    "    half = window_len//2\n",
    "    trend = np.full_like(y, np.nan, dtype=float)\n",
    "    for i in range(len(y)):\n",
    "        lo, hi = max(0, i-half), min(len(y), i+half+1)\n",
    "        tt = t[lo:hi] - t[i]; yy = y[lo:hi]\n",
    "        m  = np.isfinite(tt) & np.isfinite(yy)\n",
    "        if np.count_nonzero(m) >= polyorder+1:\n",
    "            c = np.polyfit(tt[m], yy[m], polyorder)\n",
    "            trend[i] = np.polyval(c, 0.0)\n",
    "    trend[~np.isfinite(trend)] = np.nanmedian(y)\n",
    "    return trend\n",
    "\n",
    "def custom_flatten(lc, window_days=1.0, polyorder=2):\n",
    "    \"\"\"Return a *new* LightCurve with flattened flux (no .replace() calls).\"\"\"\n",
    "    t = lc.time.value\n",
    "    f = lc.flux.value.astype(float)\n",
    "    wl = window_len_for(t, window_days)\n",
    "    tr = savgol_trend(t, f, wl, polyorder=polyorder)\n",
    "    flat = f/np.where(np.isfinite(tr), tr, np.nanmedian(f))\n",
    "    flat /= np.nanmedian(flat)\n",
    "    # carry flux_err if present\n",
    "    try:\n",
    "        ferr = lc.flux_err.value if getattr(lc, \"flux_err\", None) is not None else None\n",
    "    except Exception:\n",
    "        ferr = None\n",
    "    from lightkurve import LightCurve\n",
    "    return LightCurve(time=lc.time, flux=flat, flux_err=ferr, meta=dict(getattr(lc, \"meta\", {})))\n",
    "\n",
    "def approx_cdpp_ppm(lc, hours=1.0):\n",
    "    t = lc.time.value; f = lc.flux.value\n",
    "    dt_hr = np.nanmedian(np.diff(t))*24.0\n",
    "    if not np.isfinite(dt_hr) or dt_hr<=0: return float(\"nan\")\n",
    "    n = max(1, int(round(hours/dt_hr)))\n",
    "    run = np.convolve(f - np.nanmedian(f), np.ones(n)/n, mode=\"valid\")\n",
    "    return float(np.nanstd(run)*1e6)\n",
    "\n",
    "def get_header_sector(header):\n",
    "    # Try common sector keys; then regex fallback\n",
    "    for k in (\"SECTOR\",\"sector\",\"SEC1\"):\n",
    "        try:\n",
    "            v = header.get(k)\n",
    "            if v is not None:\n",
    "                return int(v)\n",
    "        except Exception:\n",
    "            pass\n",
    "    txt = \" \".join([f\"{k}={header.get(k)}\" for k in header.keys()])\n",
    "    m = re.search(r\"[Ss]ector[^0-9]*([0-9]{1,3})\", txt)\n",
    "    return int(m.group(1)) if m else None\n",
    "\n",
    "# --- Lightkurve ---\n",
    "import lightkurve as lk\n",
    "from lightkurve import LightCurveCollection\n",
    "\n",
    "def run_download_clean(target_toi: str, target_tic: int, quality=QUALITY, cutout_sz=CUTOUT_SZ, win_days=WIN_DAYS):\n",
    "    TARGET = f\"TIC {target_tic}\"\n",
    "    out_fig  = f\"figures/TIC{target_tic}_download_clean.png\"\n",
    "    out_json = f\"results/TIC{target_tic}_download_clean_summary.json\"\n",
    "\n",
    "    print(f\"Target: {target_toi} ({TARGET})\")\n",
    "\n",
    "    # -------------------------\n",
    "    # 1) Download SPOC PDCSAP first; read sector from files (robust to missing 'sector' column)\n",
    "    # -------------------------\n",
    "    pdcsap_list, got_spoc_sectors = [], set()\n",
    "    sr_spoc = lk.search_lightcurvefile(TARGET, mission=\"TESS\", author=\"SPOC\")\n",
    "\n",
    "    if len(sr_spoc) == 0:\n",
    "        print(\"No SPOC PDCSAP products found.\")\n",
    "    else:\n",
    "        for i in range(len(sr_spoc)):\n",
    "            try:\n",
    "                lcf = sr_spoc[i].download(download_dir=\"data_raw_fresh\")\n",
    "                lc  = lcf.PDCSAP_FLUX.remove_nans().normalize()\n",
    "                # sector from object or header\n",
    "                s = getattr(lcf, \"sector\", None)\n",
    "                if s is None:\n",
    "                    try:\n",
    "                        hdr = lcf.header() if hasattr(lcf, \"header\") else lcf.get_header()\n",
    "                    except Exception:\n",
    "                        hdr = None\n",
    "                    if hdr is not None:\n",
    "                        s = get_header_sector(hdr)\n",
    "                if s is None: s = -1\n",
    "                lc.meta[\"source\"] = \"PDCSAP\"; lc.meta[\"sector\"] = int(s)\n",
    "                pdcsap_list.append(lc)\n",
    "                if s != -1: got_spoc_sectors.add(int(s))\n",
    "                print(f\" PDCSAP S{int(s) if s!=-1 else '?'}: ok (N={len(lc)})\")\n",
    "            except Exception as e:\n",
    "                print(f\" PDCSAP entry {i}: failed -> {e}\")\n",
    "\n",
    "    # -------------------------\n",
    "    # 2) Query TESSCut and add FFI for sectors not covered by PDCSAP\n",
    "    # -------------------------\n",
    "    ffi_list = []\n",
    "    try:\n",
    "        sr_cut = lk.search_tesscut(TARGET)\n",
    "    except Exception as e:\n",
    "        sr_cut = []\n",
    "        print(\"TESSCut query failed:\", e)\n",
    "\n",
    "    if len(sr_cut) == 0:\n",
    "        print(\"No TESSCut entries found.\")\n",
    "    else:\n",
    "        for i in range(len(sr_cut)):\n",
    "            try:\n",
    "                tpf = sr_cut[i].download(cutout_size=cutout_sz, download_dir=\"data_raw_fresh\")\n",
    "                # sector from object or header\n",
    "                s = getattr(tpf, \"sector\", None)\n",
    "                if s is None:\n",
    "                    try:\n",
    "                        hdr = tpf.hdu[0].header\n",
    "                    except Exception:\n",
    "                        hdr = None\n",
    "                    if hdr is not None:\n",
    "                        s = get_header_sector(hdr)\n",
    "                if s is None: s = -1\n",
    "                # skip if PDCSAP already covers\n",
    "                if (s != -1) and (int(s) in got_spoc_sectors):\n",
    "                    print(f\"  FFI S{int(s)}: skip (already have PDCSAP)\")\n",
    "                    continue\n",
    "                # aperture photometry\n",
    "                mask = tpf.create_threshold_mask(threshold=3, reference_pixel=None)\n",
    "                if not np.any(mask):\n",
    "                    m = np.zeros_like(mask, dtype=bool)\n",
    "                    yy, xx = np.unravel_index(np.nanargmax(np.nanmedian(tpf.flux.value, axis=0)), mask.shape)\n",
    "                    m[yy, xx] = True\n",
    "                    mask = m\n",
    "                lc = tpf.to_lightcurve(aperture_mask=mask).remove_nans().normalize()\n",
    "                lc.meta[\"source\"] = \"FFI\"; lc.meta[\"sector\"] = int(s)\n",
    "                ffi_list.append(lc)\n",
    "                print(f\"  FFI S{int(s) if s!=-1 else '?'}: ok (N={len(lc)})\")\n",
    "            except Exception as e:\n",
    "                print(f\"  FFI entry {i}: failed -> {e}\")\n",
    "\n",
    "    if not (pdcsap_list or ffi_list):\n",
    "        raise RuntimeError(\"No light curves obtained from SPOC or TESSCut.\")\n",
    "\n",
    "    # -------------------------\n",
    "    # 3) Stitch, flatten, QC\n",
    "    # -------------------------\n",
    "    all_lcs_raw   = pdcsap_list + ffi_list\n",
    "    stitched_raw  = LightCurveCollection(all_lcs_raw).stitch().remove_nans()\n",
    "    stitched_flat = custom_flatten(stitched_raw, window_days=win_days)\n",
    "\n",
    "    def rms_ppm(x): return float(np.nanstd(x)*1e6)\n",
    "    qc = {\n",
    "        \"target_toi\": target_toi,\n",
    "        \"target_tic\": target_tic,\n",
    "        \"n_sectors_pdcsap\": len(pdcsap_list),\n",
    "        \"n_sectors_ffi\": len(ffi_list),\n",
    "        \"sectors_pdcsap\": [int(lc.meta.get(\"sector\", -1)) for lc in pdcsap_list],\n",
    "        \"sectors_ffi\": [int(lc.meta.get(\"sector\", -1)) for lc in ffi_list],\n",
    "        \"n_points_raw\": int(len(stitched_raw)),\n",
    "        \"n_points_flat\": int(len(stitched_flat)),\n",
    "        \"rms_raw_ppm\": rms_ppm(stitched_raw.flux.value),\n",
    "        \"rms_flat_ppm\": rms_ppm(stitched_flat.flux.value),\n",
    "        \"cdpp1h_flat_ppm\": approx_cdpp_ppm(stitched_flat, hours=1.0),\n",
    "        \"flatten_window_days\": float(win_days),\n",
    "        \"notes\": \"PDCSAP preferred; FFI(TESSCut) used where SPOC PDCSAP missing.\"\n",
    "    }\n",
    "\n",
    "    # -------------------------\n",
    "    # 4) Figure & JSON\n",
    "    # -------------------------\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12,6), dpi=140, sharex=True)\n",
    "    stitched_raw.plot(ax=ax1, marker=\".\", lw=0, alpha=0.35)\n",
    "    ax1.set_ylabel(\"Flux (norm)\")\n",
    "    ax1.set_title(f\"{target_toi} (TIC {target_tic}) — Stitched RAW\")\n",
    "    stitched_flat.plot(ax=ax2, marker=\".\", lw=0, alpha=0.45, label=\"flattened\")\n",
    "    ax2.set_xlabel(\"Time [BTJD]\")\n",
    "    ax2.set_ylabel(\"Flux (norm)\")\n",
    "    ax2.set_title(f\"{target_toi} — Stitched FLAT (window={win_days:.2f} d)\")\n",
    "    ax2.legend(loc=\"best\")\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(out_fig); plt.close(fig)\n",
    "\n",
    "    with open(out_json, \"w\") as f:\n",
    "        json.dump(qc, f, indent=2)\n",
    "\n",
    "    print(\"\\n== DONE ==\")\n",
    "    print(f\"Saved figure: {out_fig}\")\n",
    "    print(f\"Saved JSON  : {out_json}\")\n",
    "    print(\"Summary:\", qc)\n",
    "\n",
    "    return qc, out_fig, out_json\n",
    "\n",
    "# ---------- Run on Target A (deliverable) ----------\n",
    "_ = run_download_clean(TARGET_TOI, TARGET_TIC, quality=QUALITY, cutout_sz=CUTOUT_SZ, win_days=WIN_DAYS)\n",
    "\n",
    "# ---------- OPTIONAL: batch-run first 4 priority targets ----------\n",
    "# Set RUN_BATCH=True to run on the first 4 rows in results/priority_targets.csv\n",
    "RUN_BATCH = False\n",
    "if RUN_BATCH:\n",
    "    import pandas as pd\n",
    "    dfp = pd.read_csv(\"results/priority_targets.csv\")\n",
    "    # Expect columns: TIC_ID_norm, toi (string/number). Adjust if your headers differ.\n",
    "    for _, row in dfp.head(4).iterrows():\n",
    "        tic = int(row[\"TIC_ID_norm\"])\n",
    "        toi = f\"TOI {row['toi']}\"\n",
    "        try:\n",
    "            run_download_clean(toi, tic, quality=QUALITY, cutout_sz=CUTOUT_SZ, win_days=WIN_DAYS)\n",
    "        except Exception as e:\n",
    "            print(f\"[Batch] {toi} (TIC {tic}) failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7962c1f8-998c-443c-ae97-1c3aa7378a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: TOI 139.01 (TIC 62483237)\n",
      " PDCSAP S1: ok (N=18094)\n",
      " PDCSAP S28: ok (N=77241)\n",
      " PDCSAP S28: ok (N=12584)\n",
      " PDCSAP S68: ok (N=87527)\n",
      " PDCSAP S68: ok (N=14710)\n",
      "  FFI S1: skip (already have PDCSAP)\n",
      "  FFI S28: skip (already have PDCSAP)\n",
      "  FFI S68: skip (already have PDCSAP)\n",
      "  FFI S95: ok (N=10114)\n",
      "\n",
      "== DONE ==\n",
      "Saved figure: figures/TIC62483237_download_clean.png\n",
      "Saved JSON  : results/TIC62483237_download_clean_summary.json\n",
      "Summary: {'target_toi': 'TOI 139.01', 'target_tic': 62483237, 'n_sectors_pdcsap': 5, 'n_sectors_ffi': 1, 'sectors_pdcsap': [1, 28, 28, 68, 68], 'sectors_ffi': [95], 'n_points_raw': 220270, 'n_points_flat': 220270, 'rms_raw_ppm': 368080.16896247864, 'rms_flat_ppm': 167808.4942875445, 'cdpp1h_flat_ppm': 84620.20798996135, 'flatten_window_days': 1.0, 'notes': 'PDCSAP preferred; FFI(TESSCut) used where SPOC PDCSAP missing.'}\n"
     ]
    }
   ],
   "source": [
    "# 02_download_clean — Target A (PDCSAP-first, TESSCut-FFI fallback) — robust & batchable\n",
    "import json, warnings, pathlib, re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# --- Config (single-target defaults) ---\n",
    "TARGET_TOI=\"TOI 139.01\"\n",
    "TARGET_TIC=62483237\n",
    "QUALITY    = 175\n",
    "CUTOUT_SZ  = 15\n",
    "WIN_DAYS   = 1.0\n",
    "\n",
    "# --- Folders ---\n",
    "pathlib.Path(\"figures\").mkdir(exist_ok=True)\n",
    "pathlib.Path(\"results\").mkdir(exist_ok=True)\n",
    "pathlib.Path(\"data_raw_fresh\").mkdir(exist_ok=True)\n",
    "\n",
    "# --- Helpers ---\n",
    "def window_len_for(t_days, window_days=1.0):\n",
    "    dt = np.nanmedian(np.diff(t_days))\n",
    "    wl = 401 if (not np.isfinite(dt) or dt<=0) else max(5, int(round(window_days/dt)))\n",
    "    return wl if wl % 2 == 1 else wl + 1\n",
    "\n",
    "def savgol_trend(t, y, window_len, polyorder=2):\n",
    "    half = window_len//2\n",
    "    trend = np.full_like(y, np.nan, dtype=float)\n",
    "    for i in range(len(y)):\n",
    "        lo, hi = max(0, i-half), min(len(y), i+half+1)\n",
    "        tt = t[lo:hi] - t[i]; yy = y[lo:hi]\n",
    "        m  = np.isfinite(tt) & np.isfinite(yy)\n",
    "        if np.count_nonzero(m) >= polyorder+1:\n",
    "            c = np.polyfit(tt[m], yy[m], polyorder)\n",
    "            trend[i] = np.polyval(c, 0.0)\n",
    "    trend[~np.isfinite(trend)] = np.nanmedian(y)\n",
    "    return trend\n",
    "\n",
    "def custom_flatten(lc, window_days=1.0, polyorder=2):\n",
    "    \"\"\"Return a *new* LightCurve with flattened flux (no .replace() calls).\"\"\"\n",
    "    t = lc.time.value\n",
    "    f = lc.flux.value.astype(float)\n",
    "    wl = window_len_for(t, window_days)\n",
    "    tr = savgol_trend(t, f, wl, polyorder=polyorder)\n",
    "    flat = f/np.where(np.isfinite(tr), tr, np.nanmedian(f))\n",
    "    flat /= np.nanmedian(flat)\n",
    "    # carry flux_err if present\n",
    "    try:\n",
    "        ferr = lc.flux_err.value if getattr(lc, \"flux_err\", None) is not None else None\n",
    "    except Exception:\n",
    "        ferr = None\n",
    "    from lightkurve import LightCurve\n",
    "    return LightCurve(time=lc.time, flux=flat, flux_err=ferr, meta=dict(getattr(lc, \"meta\", {})))\n",
    "\n",
    "def approx_cdpp_ppm(lc, hours=1.0):\n",
    "    t = lc.time.value; f = lc.flux.value\n",
    "    dt_hr = np.nanmedian(np.diff(t))*24.0\n",
    "    if not np.isfinite(dt_hr) or dt_hr<=0: return float(\"nan\")\n",
    "    n = max(1, int(round(hours/dt_hr)))\n",
    "    run = np.convolve(f - np.nanmedian(f), np.ones(n)/n, mode=\"valid\")\n",
    "    return float(np.nanstd(run)*1e6)\n",
    "\n",
    "def get_header_sector(header):\n",
    "    # Try common sector keys; then regex fallback\n",
    "    for k in (\"SECTOR\",\"sector\",\"SEC1\"):\n",
    "        try:\n",
    "            v = header.get(k)\n",
    "            if v is not None:\n",
    "                return int(v)\n",
    "        except Exception:\n",
    "            pass\n",
    "    txt = \" \".join([f\"{k}={header.get(k)}\" for k in header.keys()])\n",
    "    m = re.search(r\"[Ss]ector[^0-9]*([0-9]{1,3})\", txt)\n",
    "    return int(m.group(1)) if m else None\n",
    "\n",
    "# --- Lightkurve ---\n",
    "import lightkurve as lk\n",
    "from lightkurve import LightCurveCollection\n",
    "\n",
    "def run_download_clean(target_toi: str, target_tic: int, quality=QUALITY, cutout_sz=CUTOUT_SZ, win_days=WIN_DAYS):\n",
    "    TARGET = f\"TIC {target_tic}\"\n",
    "    out_fig  = f\"figures/TIC{target_tic}_download_clean.png\"\n",
    "    out_json = f\"results/TIC{target_tic}_download_clean_summary.json\"\n",
    "\n",
    "    print(f\"Target: {target_toi} ({TARGET})\")\n",
    "\n",
    "    # -------------------------\n",
    "    # 1) Download SPOC PDCSAP first; read sector from files (robust to missing 'sector' column)\n",
    "    # -------------------------\n",
    "    pdcsap_list, got_spoc_sectors = [], set()\n",
    "    sr_spoc = lk.search_lightcurvefile(TARGET, mission=\"TESS\", author=\"SPOC\")\n",
    "\n",
    "    if len(sr_spoc) == 0:\n",
    "        print(\"No SPOC PDCSAP products found.\")\n",
    "    else:\n",
    "        for i in range(len(sr_spoc)):\n",
    "            try:\n",
    "                lcf = sr_spoc[i].download(download_dir=\"data_raw_fresh\")\n",
    "                lc  = lcf.PDCSAP_FLUX.remove_nans().normalize()\n",
    "                # sector from object or header\n",
    "                s = getattr(lcf, \"sector\", None)\n",
    "                if s is None:\n",
    "                    try:\n",
    "                        hdr = lcf.header() if hasattr(lcf, \"header\") else lcf.get_header()\n",
    "                    except Exception:\n",
    "                        hdr = None\n",
    "                    if hdr is not None:\n",
    "                        s = get_header_sector(hdr)\n",
    "                if s is None: s = -1\n",
    "                lc.meta[\"source\"] = \"PDCSAP\"; lc.meta[\"sector\"] = int(s)\n",
    "                pdcsap_list.append(lc)\n",
    "                if s != -1: got_spoc_sectors.add(int(s))\n",
    "                print(f\" PDCSAP S{int(s) if s!=-1 else '?'}: ok (N={len(lc)})\")\n",
    "            except Exception as e:\n",
    "                print(f\" PDCSAP entry {i}: failed -> {e}\")\n",
    "\n",
    "    # -------------------------\n",
    "    # 2) Query TESSCut and add FFI for sectors not covered by PDCSAP\n",
    "    # -------------------------\n",
    "    ffi_list = []\n",
    "    try:\n",
    "        sr_cut = lk.search_tesscut(TARGET)\n",
    "    except Exception as e:\n",
    "        sr_cut = []\n",
    "        print(\"TESSCut query failed:\", e)\n",
    "\n",
    "    if len(sr_cut) == 0:\n",
    "        print(\"No TESSCut entries found.\")\n",
    "    else:\n",
    "        for i in range(len(sr_cut)):\n",
    "            try:\n",
    "                tpf = sr_cut[i].download(cutout_size=cutout_sz, download_dir=\"data_raw_fresh\")\n",
    "                # sector from object or header\n",
    "                s = getattr(tpf, \"sector\", None)\n",
    "                if s is None:\n",
    "                    try:\n",
    "                        hdr = tpf.hdu[0].header\n",
    "                    except Exception:\n",
    "                        hdr = None\n",
    "                    if hdr is not None:\n",
    "                        s = get_header_sector(hdr)\n",
    "                if s is None: s = -1\n",
    "                # skip if PDCSAP already covers\n",
    "                if (s != -1) and (int(s) in got_spoc_sectors):\n",
    "                    print(f\"  FFI S{int(s)}: skip (already have PDCSAP)\")\n",
    "                    continue\n",
    "                # aperture photometry\n",
    "                mask = tpf.create_threshold_mask(threshold=3, reference_pixel=None)\n",
    "                if not np.any(mask):\n",
    "                    m = np.zeros_like(mask, dtype=bool)\n",
    "                    yy, xx = np.unravel_index(np.nanargmax(np.nanmedian(tpf.flux.value, axis=0)), mask.shape)\n",
    "                    m[yy, xx] = True\n",
    "                    mask = m\n",
    "                lc = tpf.to_lightcurve(aperture_mask=mask).remove_nans().normalize()\n",
    "                lc.meta[\"source\"] = \"FFI\"; lc.meta[\"sector\"] = int(s)\n",
    "                ffi_list.append(lc)\n",
    "                print(f\"  FFI S{int(s) if s!=-1 else '?'}: ok (N={len(lc)})\")\n",
    "            except Exception as e:\n",
    "                print(f\"  FFI entry {i}: failed -> {e}\")\n",
    "\n",
    "    if not (pdcsap_list or ffi_list):\n",
    "        raise RuntimeError(\"No light curves obtained from SPOC or TESSCut.\")\n",
    "\n",
    "    # -------------------------\n",
    "    # 3) Stitch, flatten, QC\n",
    "    # -------------------------\n",
    "    all_lcs_raw   = pdcsap_list + ffi_list\n",
    "    stitched_raw  = LightCurveCollection(all_lcs_raw).stitch().remove_nans()\n",
    "    stitched_flat = custom_flatten(stitched_raw, window_days=win_days)\n",
    "\n",
    "    def rms_ppm(x): return float(np.nanstd(x)*1e6)\n",
    "    qc = {\n",
    "        \"target_toi\": target_toi,\n",
    "        \"target_tic\": target_tic,\n",
    "        \"n_sectors_pdcsap\": len(pdcsap_list),\n",
    "        \"n_sectors_ffi\": len(ffi_list),\n",
    "        \"sectors_pdcsap\": [int(lc.meta.get(\"sector\", -1)) for lc in pdcsap_list],\n",
    "        \"sectors_ffi\": [int(lc.meta.get(\"sector\", -1)) for lc in ffi_list],\n",
    "        \"n_points_raw\": int(len(stitched_raw)),\n",
    "        \"n_points_flat\": int(len(stitched_flat)),\n",
    "        \"rms_raw_ppm\": rms_ppm(stitched_raw.flux.value),\n",
    "        \"rms_flat_ppm\": rms_ppm(stitched_flat.flux.value),\n",
    "        \"cdpp1h_flat_ppm\": approx_cdpp_ppm(stitched_flat, hours=1.0),\n",
    "        \"flatten_window_days\": float(win_days),\n",
    "        \"notes\": \"PDCSAP preferred; FFI(TESSCut) used where SPOC PDCSAP missing.\"\n",
    "    }\n",
    "\n",
    "    # -------------------------\n",
    "    # 4) Figure & JSON\n",
    "    # -------------------------\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12,6), dpi=140, sharex=True)\n",
    "    stitched_raw.plot(ax=ax1, marker=\".\", lw=0, alpha=0.35)\n",
    "    ax1.set_ylabel(\"Flux (norm)\")\n",
    "    ax1.set_title(f\"{target_toi} (TIC {target_tic}) — Stitched RAW\")\n",
    "    stitched_flat.plot(ax=ax2, marker=\".\", lw=0, alpha=0.45, label=\"flattened\")\n",
    "    ax2.set_xlabel(\"Time [BTJD]\")\n",
    "    ax2.set_ylabel(\"Flux (norm)\")\n",
    "    ax2.set_title(f\"{target_toi} — Stitched FLAT (window={win_days:.2f} d)\")\n",
    "    ax2.legend(loc=\"best\")\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(out_fig); plt.close(fig)\n",
    "\n",
    "    with open(out_json, \"w\") as f:\n",
    "        json.dump(qc, f, indent=2)\n",
    "\n",
    "    print(\"\\n== DONE ==\")\n",
    "    print(f\"Saved figure: {out_fig}\")\n",
    "    print(f\"Saved JSON  : {out_json}\")\n",
    "    print(\"Summary:\", qc)\n",
    "\n",
    "    return qc, out_fig, out_json\n",
    "\n",
    "# ---------- Run on Target A (deliverable) ----------\n",
    "_ = run_download_clean(TARGET_TOI, TARGET_TIC, quality=QUALITY, cutout_sz=CUTOUT_SZ, win_days=WIN_DAYS)\n",
    "\n",
    "# ---------- OPTIONAL: batch-run first 4 priority targets ----------\n",
    "# Set RUN_BATCH=True to run on the first 4 rows in results/priority_targets.csv\n",
    "RUN_BATCH = False\n",
    "if RUN_BATCH:\n",
    "    import pandas as pd\n",
    "    dfp = pd.read_csv(\"results/priority_targets.csv\")\n",
    "    # Expect columns: TIC_ID_norm, toi (string/number). Adjust if your headers differ.\n",
    "    for _, row in dfp.head(4).iterrows():\n",
    "        tic = int(row[\"TIC_ID_norm\"])\n",
    "        toi = f\"TOI {row['toi']}\"\n",
    "        try:\n",
    "            run_download_clean(toi, tic, quality=QUALITY, cutout_sz=CUTOUT_SZ, win_days=WIN_DAYS)\n",
    "        except Exception as e:\n",
    "            print(f\"[Batch] {toi} (TIC {tic}) failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ab71a61-cda8-418f-b051-f0893c733f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: TOI 1801.01 (TIC 119584412)\n",
      " PDCSAP S22: ok (N=16101)\n",
      " PDCSAP S49: ok (N=13272)\n",
      "  FFI S22: skip (already have PDCSAP)\n",
      "  FFI S49: skip (already have PDCSAP)\n",
      "\n",
      "== DONE ==\n",
      "Saved figure: figures/TIC119584412_download_clean.png\n",
      "Saved JSON  : results/TIC119584412_download_clean_summary.json\n",
      "Summary: {'target_toi': 'TOI 1801.01', 'target_tic': 119584412, 'n_sectors_pdcsap': 2, 'n_sectors_ffi': 0, 'sectors_pdcsap': [22, 49], 'sectors_ffi': [], 'n_points_raw': 29370, 'n_points_flat': 29370, 'rms_raw_ppm': 1356.3033426180482, 'rms_flat_ppm': 1096.2121625978075, 'cdpp1h_flat_ppm': 251.0249996146523, 'flatten_window_days': 1.0, 'notes': 'PDCSAP preferred; FFI(TESSCut) only when SPOC PDCSAP is missing.'}\n"
     ]
    }
   ],
   "source": [
    "# 02_download_clean — PDCSAP-first, TESSCut-FFI fallback (ONE-CELL VERSION)\n",
    "# “PDCSAP first; FFI fallback; stitched + flattened; saves figure + QC.”\n",
    "# ---- EDIT THESE TWO LINES ONLY ----\n",
    "TARGET_TOI = \"TOI 1801.01\"   # label for plots\n",
    "TARGET_TIC = 119584412       # integer TIC ID\n",
    "# -----------------------------------\n",
    "\n",
    "import json, warnings, pathlib, re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# --- Config ---\n",
    "QUALITY    = 175         # standard TESS quality mask (matches Lightkurve’s default)\n",
    "CUTOUT_SZ  = 15          # TESSCut postage-stamp size (pixels)\n",
    "WIN_DAYS   = 1.0         # flattening window (days) – gentle, won’t erase hour-long dips\n",
    "OUT_FIG    = f\"figures/TIC{TARGET_TIC}_download_clean.png\"\n",
    "OUT_JSON   = f\"results/TIC{TARGET_TIC}_download_clean_summary.json\"\n",
    "TARGET     = f\"TIC {TARGET_TIC}\"\n",
    "\n",
    "# --- Make folders ---\n",
    "for d in [\"figures\", \"results\", \"data_raw_fresh\"]:\n",
    "    pathlib.Path(d).mkdir(exist_ok=True)\n",
    "\n",
    "# --- Helpers ---\n",
    "def window_len_for(t_days, window_days=1.0):\n",
    "    dt = np.nanmedian(np.diff(t_days))\n",
    "    wl = 401 if (not np.isfinite(dt) or dt<=0) else max(5, int(round(window_days/dt)))\n",
    "    return wl if wl % 2 == 1 else wl + 1\n",
    "\n",
    "def savgol_trend(t, y, window_len, polyorder=2):\n",
    "    half = window_len//2\n",
    "    trend = np.full_like(y, np.nan, dtype=float)\n",
    "    for i in range(len(y)):\n",
    "        lo, hi = max(0, i-half), min(len(y), i+half+1)\n",
    "        tt = t[lo:hi] - t[i]; yy = y[lo:hi]\n",
    "        m = np.isfinite(tt) & np.isfinite(yy)\n",
    "        if np.count_nonzero(m) >= polyorder+1:\n",
    "            c = np.polyfit(tt[m], yy[m], polyorder)\n",
    "            trend[i] = np.polyval(c, 0.0)\n",
    "    trend[~np.isfinite(trend)] = np.nanmedian(y)\n",
    "    return trend\n",
    "\n",
    "def custom_flatten(lc, window_days=1.0, polyorder=2):\n",
    "    \"\"\"Return a NEW LightCurve with same time, flattened flux (median=1).\"\"\"\n",
    "    from lightkurve import LightCurve\n",
    "    t = lc.time.value\n",
    "    f = lc.flux.value.astype(float)\n",
    "    wl = window_len_for(t, window_days)\n",
    "    tr = savgol_trend(t, f, wl, polyorder=polyorder)\n",
    "    flat = f/np.where(np.isfinite(tr), tr, np.nanmedian(f))\n",
    "    flat /= np.nanmedian(flat)\n",
    "    return LightCurve(time=lc.time, flux=flat, flux_err=getattr(lc, \"flux_err\", None), meta=lc.meta)\n",
    "\n",
    "def approx_cdpp_ppm(lc, hours=1.0):\n",
    "    t = lc.time.value; f = lc.flux.value\n",
    "    dt_hr = np.nanmedian(np.diff(t))*24.0\n",
    "    if not np.isfinite(dt_hr) or dt_hr<=0: return float(\"nan\")\n",
    "    n = max(1, int(round(hours/dt_hr)))\n",
    "    run = np.convolve(f - np.nanmedian(f), np.ones(n)/n, mode=\"valid\")\n",
    "    return float(np.nanstd(run)*1e6)\n",
    "\n",
    "def get_header_sector(header):\n",
    "    for k in (\"SECTOR\",\"sector\",\"SEC1\"):\n",
    "        try:\n",
    "            v = header.get(k)\n",
    "            if v is not None:\n",
    "                return int(v)\n",
    "        except Exception:\n",
    "            pass\n",
    "    txt = \" \".join([f\"{k}={header.get(k)}\" for k in header.keys()])\n",
    "    m = re.search(r\"[Ss]ector[^0-9]*([0-9]{1,3})\", txt)\n",
    "    return int(m.group(1)) if m else None\n",
    "\n",
    "def robust_ylim(flux, lo=0.2, hi=99.8):\n",
    "    lo_, hi_ = np.nanpercentile(flux, [lo, hi])\n",
    "    pad = 0.03*(hi_ - lo_)\n",
    "    return lo_-pad, hi_+pad\n",
    "\n",
    "def apply_quality_mask(lc, bitmask=QUALITY):\n",
    "    \"\"\"Keep cadences where (quality & ~bitmask)==0, i.e., standard good cadences.\"\"\"\n",
    "    q = getattr(lc, \"quality\", None)\n",
    "    if q is None:\n",
    "        return lc\n",
    "    good = (q & ~bitmask) == 0\n",
    "    return lc[good]\n",
    "\n",
    "# --- Lightkurve imports ---\n",
    "import lightkurve as lk\n",
    "from lightkurve import LightCurveCollection\n",
    "\n",
    "print(f\"Target: {TARGET_TOI} ({TARGET})\")\n",
    "\n",
    "# =========================\n",
    "# 1) PDCSAP (SPOC) download\n",
    "# =========================\n",
    "pdcsap_list, got_spoc_sectors = [], set()\n",
    "sr_spoc = lk.search_lightcurvefile(TARGET, mission=\"TESS\", author=\"SPOC\")\n",
    "\n",
    "if len(sr_spoc) == 0:\n",
    "    print(\"No SPOC PDCSAP products found.\")\n",
    "else:\n",
    "    for i in range(len(sr_spoc)):\n",
    "        try:\n",
    "            lcf = sr_spoc[i].download(download_dir=\"data_raw_fresh\")\n",
    "            lc  = lcf.PDCSAP_FLUX.remove_nans().normalize()\n",
    "            lc  = apply_quality_mask(lc, QUALITY)\n",
    "\n",
    "            # sector from object or header\n",
    "            s = getattr(lcf, \"sector\", None)\n",
    "            if s is None:\n",
    "                hdr = None\n",
    "                try:\n",
    "                    hdr = lcf.header() if hasattr(lcf, \"header\") else lcf.get_header()\n",
    "                except Exception:\n",
    "                    pass\n",
    "                if hdr is not None:\n",
    "                    s = get_header_sector(hdr)\n",
    "            if s is None: s = -1\n",
    "\n",
    "            lc.meta[\"source\"] = \"PDCSAP\"; lc.meta[\"sector\"] = int(s)\n",
    "            pdcsap_list.append(lc)\n",
    "            if s != -1: got_spoc_sectors.add(int(s))\n",
    "            print(f\" PDCSAP S{int(s) if s!=-1 else '?'}: ok (N={len(lc)})\")\n",
    "        except Exception as e:\n",
    "            print(f\" PDCSAP entry {i}: failed -> {e}\")\n",
    "\n",
    "# ==============================\n",
    "# 2) TESSCut (FFI) for gaps only\n",
    "# ==============================\n",
    "ffi_list = []\n",
    "try:\n",
    "    sr_cut = lk.search_tesscut(TARGET)\n",
    "except Exception as e:\n",
    "    sr_cut = []\n",
    "    print(\"TESSCut query failed:\", e)\n",
    "\n",
    "if len(sr_cut) == 0:\n",
    "    print(\"No TESSCut entries found.\")\n",
    "else:\n",
    "    for i in range(len(sr_cut)):\n",
    "        try:\n",
    "            tpf = sr_cut[i].download(cutout_size=CUTOUT_SZ, download_dir=\"data_raw_fresh\")\n",
    "            s = getattr(tpf, \"sector\", None)\n",
    "            if s is None:\n",
    "                hdr = None\n",
    "                try:\n",
    "                    hdr = tpf.hdu[0].header\n",
    "                except Exception:\n",
    "                    pass\n",
    "                if hdr is not None:\n",
    "                    s = get_header_sector(hdr)\n",
    "            if s is None: s = -1\n",
    "\n",
    "            if (s != -1) and (int(s) in got_spoc_sectors):\n",
    "                print(f\"  FFI S{int(s)}: skip (already have PDCSAP)\")\n",
    "                continue\n",
    "\n",
    "            mask = tpf.create_threshold_mask(threshold=3, reference_pixel=None)\n",
    "            if not np.any(mask):\n",
    "                m = np.zeros_like(mask, dtype=bool)\n",
    "                yy, xx = np.unravel_index(np.nanargmax(np.nanmedian(tpf.flux.value, axis=0)), mask.shape)\n",
    "                m[yy, xx] = True\n",
    "                mask = m\n",
    "\n",
    "            lc = tpf.to_lightcurve(aperture_mask=mask).remove_nans().normalize()\n",
    "            lc = apply_quality_mask(lc, QUALITY)\n",
    "            lc.meta[\"source\"] = \"FFI\"; lc.meta[\"sector\"] = int(s)\n",
    "            ffi_list.append(lc)\n",
    "            print(f\"  FFI S{int(s) if s!=-1 else '?'}: ok (N={len(lc)})\")\n",
    "        except Exception as e:\n",
    "            print(f\"  FFI entry {i}: failed -> {e}\")\n",
    "\n",
    "if not (pdcsap_list or ffi_list):\n",
    "    raise RuntimeError(\"No light curves obtained from SPOC or TESSCut.\")\n",
    "\n",
    "# =======================\n",
    "# 3) Stitch, clean, QC\n",
    "# =======================\n",
    "all_lcs_raw   = pdcsap_list + ffi_list\n",
    "stitched_raw  = LightCurveCollection(all_lcs_raw).stitch().remove_nans()\n",
    "\n",
    "# very light outlier clip (protects plots; safe for downloader stage)\n",
    "f = stitched_raw.flux.value\n",
    "med, sig = np.nanmedian(f), np.nanstd(f)\n",
    "m = (f > med - 5*sig) & (f < med + 5*sig)\n",
    "stitched_raw = stitched_raw[m]\n",
    "\n",
    "stitched_flat = custom_flatten(stitched_raw, window_days=WIN_DAYS)\n",
    "\n",
    "def rms_ppm(x): return float(np.nanstd(x)*1e6)\n",
    "qc = {\n",
    "    \"target_toi\": TARGET_TOI,\n",
    "    \"target_tic\": int(TARGET_TIC),\n",
    "    \"n_sectors_pdcsap\": len(pdcsap_list),\n",
    "    \"n_sectors_ffi\": len(ffi_list),\n",
    "    \"sectors_pdcsap\": [int(lc.meta.get(\"sector\", -1)) for lc in pdcsap_list],\n",
    "    \"sectors_ffi\": [int(lc.meta.get(\"sector\", -1)) for lc in ffi_list],\n",
    "    \"n_points_raw\": int(len(stitched_raw)),\n",
    "    \"n_points_flat\": int(len(stitched_flat)),\n",
    "    \"rms_raw_ppm\": rms_ppm(stitched_raw.flux.value),\n",
    "    \"rms_flat_ppm\": rms_ppm(stitched_flat.flux.value),\n",
    "    \"cdpp1h_flat_ppm\": approx_cdpp_ppm(stitched_flat, hours=1.0),\n",
    "    \"flatten_window_days\": WIN_DAYS,\n",
    "    \"notes\": \"PDCSAP preferred; FFI(TESSCut) only when SPOC PDCSAP is missing.\"\n",
    "}\n",
    "\n",
    "# =======================\n",
    "# 4) Figure + JSON output\n",
    "# =======================\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12,6), dpi=140, sharex=True)\n",
    "t0 = 2457000.0\n",
    "\n",
    "ax1.scatter(stitched_raw.time.value, stitched_raw.flux.value, s=2, alpha=0.35)\n",
    "ax1.set_ylabel(\"Flux (norm)\")\n",
    "ax1.set_title(f\"{TARGET_TOI} ({TARGET}) — Stitched RAW\")\n",
    "\n",
    "ax2.scatter(stitched_flat.time.value, stitched_flat.flux.value, s=2, alpha=0.45, label=\"flattened\")\n",
    "ax2.set_xlabel(\"Time [BTJD]\")\n",
    "ax2.set_ylabel(\"Flux (norm)\")\n",
    "ax2.set_title(f\"{TARGET_TOI} — Stitched FLAT (window={WIN_DAYS:.2f} d)\")\n",
    "ax2.legend(loc=\"best\")\n",
    "\n",
    "# keep y-axes sensible even if an FFI chunk is wild\n",
    "y1_lo, y1_hi = robust_ylim(stitched_raw.flux.value)\n",
    "y2_lo, y2_hi = robust_ylim(stitched_flat.flux.value)\n",
    "ax1.set_ylim(y1_lo, y1_hi)\n",
    "ax2.set_ylim(y2_lo, y2_hi)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(OUT_FIG); plt.close(fig)\n",
    "\n",
    "with open(OUT_JSON, \"w\") as f:\n",
    "    json.dump(qc, f, indent=2)\n",
    "\n",
    "print(\"\\n== DONE ==\")\n",
    "print(f\"Saved figure: {OUT_FIG}\")\n",
    "print(f\"Saved JSON  : {OUT_JSON}\")\n",
    "print(\"Summary:\", qc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e3b4630-d025-49e7-b31b-8a48b322992a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-sector QA complete: saved 2 plots to figures/ and summary to results/QA_TIC119584412_summary.json\n",
      " S22: PDCSAP, N_use=16101/16101, frac_bad=0.0, cdpp1h_ppm=740\n",
      " S49: PDCSAP, N_use=13272/13272, frac_bad=0.0, cdpp1h_ppm=937\n"
     ]
    }
   ],
   "source": [
    "# === Per-sector QA (robust: handles Time/Quantity types) ===\n",
    "import numpy as np, matplotlib.pyplot as plt, pathlib, json\n",
    "import lightkurve as lk\n",
    "\n",
    "TIC = TARGET_TIC\n",
    "BASE = f\"TIC{TIC}\"\n",
    "pathlib.Path(\"figures\").mkdir(exist_ok=True)\n",
    "pathlib.Path(\"results\").mkdir(exist_ok=True)\n",
    "\n",
    "def as_float_array(x):\n",
    "    \"\"\"Return a float numpy array from Lightkurve/astropy containers.\"\"\"\n",
    "    # Try .value (Quantity/Time), else assume it's already an array-like\n",
    "    try:\n",
    "        x = x.value\n",
    "    except Exception:\n",
    "        pass\n",
    "    return np.asarray(x, dtype=float)\n",
    "\n",
    "def rms_ppm(y):\n",
    "    y = as_float_array(y)\n",
    "    return float(np.nanstd(y) * 1e6)\n",
    "\n",
    "def cdpp_ppm(time, flux, hours=1.0):\n",
    "    t = as_float_array(time)\n",
    "    f = as_float_array(flux)\n",
    "    dt = np.nanmedian(np.diff(t))\n",
    "    if not np.isfinite(dt) or dt <= 0:\n",
    "        return float(\"nan\")\n",
    "    n = max(1, int(round((hours/24.0)/dt)))\n",
    "    run = np.convolve(f - np.nanmedian(f), np.ones(n)/n, mode=\"valid\")\n",
    "    return float(np.nanstd(run)*1e6)\n",
    "\n",
    "def build_quality_mask(lc, quality_bitmask):\n",
    "    q = getattr(lc, \"quality\", None)\n",
    "    if q is not None and len(q) == len(lc.flux):\n",
    "        try:\n",
    "            return lk.utils.TessQualityFlags.create_quality_mask(q, bitmask=quality_bitmask)\n",
    "        except Exception:\n",
    "            return np.ones(len(lc.flux), dtype=bool)\n",
    "    return np.ones(len(lc.flux), dtype=bool)\n",
    "\n",
    "entries = []\n",
    "for src_list in (pdcsap_list, ffi_list):\n",
    "    for lc in src_list:\n",
    "        # sector & source tags\n",
    "        try:\n",
    "            sector = int(lc.meta.get(\"sector\", -1))\n",
    "        except Exception:\n",
    "            sector = -1\n",
    "        src_lbl = \"PDCSAP\" if lc.meta.get(\"source\") == \"PDCSAP\" else \"FFI\"\n",
    "\n",
    "        # arrays\n",
    "        t_all = as_float_array(lc.time)\n",
    "        f_all = as_float_array(lc.flux)\n",
    "\n",
    "        # masks\n",
    "        qmask  = build_quality_mask(lc, QUALITY)\n",
    "        finite = np.isfinite(t_all) & np.isfinite(f_all)\n",
    "        m = qmask & finite\n",
    "\n",
    "        N_all = int(len(f_all))\n",
    "        N_use = int(np.count_nonzero(m))\n",
    "        frac_bad = float(1 - (N_use / max(N_all, 1)))\n",
    "\n",
    "        # plot with plain arrays\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(11, 3), dpi=140)\n",
    "        ax.plot(t_all[m], f_all[m], \".\", ms=2, alpha=0.7)\n",
    "        ax.set_title(f\"{TARGET_TOI} S{sector if sector!=-1 else '?'} — {src_lbl}\")\n",
    "        ax.set_xlabel(\"Time [BTJD]\"); ax.set_ylabel(\"Flux (norm)\")\n",
    "        out_png = f\"figures/QA_{BASE}_S{sector if sector!=-1 else 'u'}.png\"\n",
    "        fig.tight_layout(); fig.savefig(out_png); plt.close(fig)\n",
    "\n",
    "        # metrics\n",
    "        entries.append({\n",
    "            \"sector\": sector,\n",
    "            \"source\": src_lbl,\n",
    "            \"N_all\": N_all,\n",
    "            \"N_use\": N_use,\n",
    "            \"frac_bad\": round(frac_bad, 4),\n",
    "            \"rms_ppm\": rms_ppm(f_all[m]),\n",
    "            \"cdpp1h_ppm\": cdpp_ppm(t_all[m], f_all[m]),\n",
    "        })\n",
    "\n",
    "if not entries:\n",
    "    raise RuntimeError(\"No sectors could be processed for QA (empty entries).\")\n",
    "\n",
    "# sort & save summary\n",
    "entries = sorted(entries, key=lambda d: (d[\"sector\"], d[\"source\"]))\n",
    "out_json = f\"results/QA_{BASE}_summary.json\"\n",
    "with open(out_json, \"w\") as f:\n",
    "    json.dump(entries, f, indent=2)\n",
    "\n",
    "print(f\"Per-sector QA complete: saved {len(entries)} plots to figures/ and summary to {out_json}\")\n",
    "for e in entries:\n",
    "    cdpp_int = int(e['cdpp1h_ppm']) if np.isfinite(e['cdpp1h_ppm']) else 'nan'\n",
    "    print(f\" S{e['sector']}: {e['source']}, N_use={e['N_use']}/{e['N_all']}, \"\n",
    "          f\"frac_bad={e['frac_bad']}, cdpp1h_ppm={cdpp_int}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f111e26-ed7f-4d71-9c80-37f8673f6fc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tess-ephem)",
   "language": "python",
   "name": "tess-ephem"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
